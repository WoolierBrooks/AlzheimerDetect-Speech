{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Open in Colab](https://colab.research.google.com/github/WoolierBrooks/DementiaDetect-Speech/blob/main/scripts/adress_2020/00_Complete_nb.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar o dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44e-05 4.17e-14 1.44e-05 ... 1.68e+00 1.35e+00 3.03e+00]\n",
      " [5.98e-06 4.17e-14 5.98e-06 ... 0.00e+00 0.00e+00 0.00e+00]\n",
      " [2.53e-05 0.00e+00 2.53e-05 ... 1.08e+00 9.27e-01 2.01e+00]\n",
      " ...\n",
      " [7.31e-05 0.00e+00 7.31e-05 ... 1.61e+00 1.64e+00 3.25e+00]\n",
      " [4.19e-05 5.43e-13 4.19e-05 ... 1.74e+00 1.78e+00 3.52e+00]\n",
      " [7.20e-05 3.34e-13 7.20e-05 ... 1.96e+00 1.72e+00 3.68e+00]] (108, 988)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (108,)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"adress_20_db_emobase_train.csv\")\n",
    "X_train = dataset.iloc[:, :-1].values\n",
    "y_train = dataset.iloc[:, -1].values\n",
    "print(X_train, X_train.shape)\n",
    "print(y_train, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando o dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.10e-05 4.17e-14 6.10e-05 ... 1.41e+00 1.42e+00 2.83e+00]\n",
      " [2.30e-08 0.00e+00 2.30e-08 ... 0.00e+00 0.00e+00 0.00e+00]\n",
      " [3.15e-05 0.00e+00 3.15e-05 ... 1.17e+00 1.14e+00 2.31e+00]\n",
      " ...\n",
      " [2.00e-05 4.17e-14 2.00e-05 ... 5.32e-01 3.84e-01 9.16e-01]\n",
      " [4.40e-05 0.00e+00 4.40e-05 ... 1.30e+00 1.15e+00 2.45e+00]\n",
      " [1.58e-06 4.17e-14 1.58e-06 ... 1.16e+00 1.39e+00 2.56e+00]] (48, 988)\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.] (48,)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"adress_20_db_emobase_test.csv\")\n",
    "X_test = dataset.iloc[:, :-1].values\n",
    "y_test = dataset.iloc[:, -1].values\n",
    "print(X_test, X_test.shape)\n",
    "print(y_test, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completando dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44e-05 4.17e-14 1.44e-05 ... 1.68e+00 1.35e+00 3.03e+00]\n",
      " [5.98e-06 4.17e-14 5.98e-06 ... 0.00e+00 0.00e+00 0.00e+00]\n",
      " [2.53e-05 0.00e+00 2.53e-05 ... 1.08e+00 9.27e-01 2.01e+00]\n",
      " ...\n",
      " [7.31e-05 0.00e+00 7.31e-05 ... 1.61e+00 1.64e+00 3.25e+00]\n",
      " [4.19e-05 5.43e-13 4.19e-05 ... 1.74e+00 1.78e+00 3.52e+00]\n",
      " [7.20e-05 3.34e-13 7.20e-05 ... 1.96e+00 1.72e+00 3.68e+00]] (108, 988)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Conjunto de treino\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "print(X_train, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.10e-05 4.17e-14 6.10e-05 ... 1.41e+00 1.42e+00 2.83e+00]\n",
      " [2.30e-08 0.00e+00 2.30e-08 ... 0.00e+00 0.00e+00 0.00e+00]\n",
      " [3.15e-05 0.00e+00 3.15e-05 ... 1.17e+00 1.14e+00 2.31e+00]\n",
      " ...\n",
      " [2.00e-05 4.17e-14 2.00e-05 ... 5.32e-01 3.84e-01 9.16e-01]\n",
      " [4.40e-05 0.00e+00 4.40e-05 ... 1.30e+00 1.15e+00 2.45e+00]\n",
      " [1.58e-06 4.17e-14 1.58e-06 ... 1.16e+00 1.39e+00 2.56e+00]] (48, 988)\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de teste\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(X_test)\n",
    "X_test = imputer.transform(X_test)\n",
    "print(X_test, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalonamento de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39577152 -0.21254338 -0.39577152 ...  0.70402515  0.40177223\n",
      "   0.55626519]\n",
      " [-0.55834326 -0.21254338 -0.55834326 ... -1.03157583 -1.01495572\n",
      "  -1.02738984]\n",
      " [-0.18531641 -0.23891375 -0.18531641 ...  0.08416766 -0.04213586\n",
      "   0.02315359]\n",
      " ...\n",
      " [ 0.7375968  -0.23891375  0.7375968  ...  0.63170844  0.70610639\n",
      "   0.67125004]\n",
      " [ 0.1351932   0.10447027  0.1351932  ...  0.7660109   0.85302632\n",
      "   0.81236781]\n",
      " [ 0.71635821 -0.02769779  0.71635821 ...  0.99329198  0.79006064\n",
      "   0.89599316]] (108, 988)\n",
      "[[ 0.50397233 -0.21254338  0.50397233 ...  0.42508928  0.4752322\n",
      "   0.4517335 ]\n",
      " [-0.67335987 -0.23891375 -0.67335987 ... -1.03157583 -1.01495572\n",
      "  -1.02738984]\n",
      " [-0.065608   -0.23891375 -0.065608   ...  0.17714628  0.18139233\n",
      "   0.17995112]\n",
      " ...\n",
      " [-0.28764779 -0.21254338 -0.28764779 ... -0.48196885 -0.61197533\n",
      "  -0.54863472]\n",
      " [ 0.17573959 -0.23891375  0.17573959 ...  0.31144874  0.19188661\n",
      "   0.2531233 ]\n",
      " [-0.64329761 -0.21254338 -0.64329761 ...  0.16681532  0.44374936\n",
      "   0.31061573]] (48, 988)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train, X_train.shape)\n",
    "print(X_test, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 60.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instanciando o classificador LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Treinando o modelo LDA com os dados de treinamento\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Realizando previsões nos dados de teste\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Calculando a precisão da classificação\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 41.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicializa o classificador de árvore de decisão\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Treina o classificador com o conjunto de treino\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Realiza a previsão com o conjunto de teste\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calcula a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Rede Neural Simples (INN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 66.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Criando o classificador da rede neural\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Treinando o classificador\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Realizando previsões no conjunto de teste\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 72.92%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Criar um classificador SVM\n",
    "classificador_svm = SVC(kernel='linear')  # Você pode escolher o tipo de kernel desejado\n",
    "\n",
    "# Treinar o classificador SVM\n",
    "classificador_svm.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões usando o conjunto de teste\n",
    "predictions = classificador_svm.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 62.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Criando o classificador Random Forest\n",
    "classificador_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinando o classificador com os dados de treinamento\n",
    "classificador_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões com o conjunto de teste\n",
    "predictions = classificador_rf.predict(X_test)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39577152 -0.21254338 -0.39577152 ...  0.70402515  0.40177223\n",
      "   0.55626519]\n",
      " [-0.55834326 -0.21254338 -0.55834326 ... -1.03157583 -1.01495572\n",
      "  -1.02738984]\n",
      " [-0.18531641 -0.23891375 -0.18531641 ...  0.08416766 -0.04213586\n",
      "   0.02315359]\n",
      " ...\n",
      " [ 0.7375968  -0.23891375  0.7375968  ...  0.63170844  0.70610639\n",
      "   0.67125004]\n",
      " [ 0.1351932   0.10447027  0.1351932  ...  0.7660109   0.85302632\n",
      "   0.81236781]\n",
      " [ 0.71635821 -0.02769779  0.71635821 ...  0.99329198  0.79006064\n",
      "   0.89599316]] (108, 988)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (108,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train, X_train.shape)\n",
    "print(y_train, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados obtidos:\n",
    "|Características|LDA   |DT    |INN   |SVM   |RF    |Média |\n",
    "|:-------------:|:----:|:----:|:----:|:----:|:----:|:----:|\n",
    "|emobase (988)  |60.42%|41.67%|66.67%|72.92%|62.50%|60.84%|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
