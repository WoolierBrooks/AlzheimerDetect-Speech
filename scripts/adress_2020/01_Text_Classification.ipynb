{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar X_train e y_train\n",
    "\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "def load_texts_from_directory(directory, label):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".cha\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                raw_data = file.read()\n",
    "                result = chardet.detect(raw_data)\n",
    "                text = raw_data.decode(result['encoding'])\n",
    "                texts.append(text)\n",
    "                labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "# Diretórios das pastas\n",
    "negative_dir = r'C:\\Users\\Lenovo\\Desktop\\IC\\[98] ADRESS-20 Database\\ADReSS-IS2020-data\\train\\transcription\\cc'\n",
    "positive_dir = r'C:\\Users\\Lenovo\\Desktop\\IC\\[98] ADRESS-20 Database\\ADReSS-IS2020-data\\train\\transcription\\cd'\n",
    "\n",
    "# Carregar textos negativos (rótulo 0)\n",
    "x_neg, y_neg = load_texts_from_directory(negative_dir, 0)\n",
    "\n",
    "# Carregar textos positivos (rótulo 1)\n",
    "x_pos, y_pos = load_texts_from_directory(positive_dir, 1)\n",
    "\n",
    "# Combinar textos e rótulos\n",
    "x_train = x_neg + x_pos\n",
    "y_train = y_neg + y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar X_test\n",
    "\n",
    "def load_texts_from_directory(directory):\n",
    "    texts = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".cha\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                raw_data = file.read()\n",
    "                result = chardet.detect(raw_data)\n",
    "                text = raw_data.decode(result['encoding'])\n",
    "                texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# Diretório da pasta de teste\n",
    "test_dir = r'C:\\Users\\Lenovo\\Desktop\\IC\\[98] ADRESS-20 Database\\ADReSS-IS2020-data\\test\\transcription'\n",
    "\n",
    "# Carregar textos de teste\n",
    "x_test = load_texts_from_directory(test_dir)\n",
    "\n",
    "y_test = [0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def ncd(x, x2): # NCD with compressed lengths\n",
    "    x_compressed = len(gzip.compress(x.encode()))\n",
    "    x2_compressed = len(gzip.compress(x2.encode()))  \n",
    "    xx2 = len(gzip.compress((\" \".join([x,x2])).encode()))\n",
    "    return (xx2 - min(x_compressed, x2_compressed)) / max(x_compressed, x2_compressed)\n",
    "\n",
    "train_ncd = [[ncd(x_train[i], x_train[j]) for j in range(len(x_train))] for i in range(len(x_train))]\n",
    "test_ncd = [[ncd(x_test[i], x_train[j]) for j in range(len(x_train))] for i in range(len(x_test))]\n",
    "\n",
    "# KNN classification\n",
    "neigh = KNeighborsClassifier(n_neighbors=7) \n",
    "neigh.fit(train_ncd, y_train)\n",
    "\n",
    "print(\"Accuracy:\", neigh.score(test_ncd, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Number of processes to use\n",
    "NUM_PROCESSES = 8\n",
    "\n",
    "# NCD with compressed lengths\n",
    "def ncd(x, x2):\n",
    "  x_compressed = len(gzip.compress(x.encode()))\n",
    "  x2_compressed = len(gzip.compress(x2.encode()))  \n",
    "  xx2 = len(gzip.compress((\" \".join([x,x2])).encode()))\n",
    "  return (xx2 - min(x_compressed, x2_compressed)) / max(x_compressed, x2_compressed)\n",
    "\n",
    "# Initialize NCD matrices  \n",
    "train_ncd = [[0] * len(x_train) for _ in range(len(x_train))]\n",
    "test_ncd = [[0] * len(x_train) for _ in range(len(x_test))]\n",
    "\n",
    "# Helper function to compute NCD row \n",
    "def calculate_ncd_row(data_row):\n",
    "    i = data_row[0]\n",
    "    row = [ncd(data_row[1], x_train[j]) for j in range(len(x_train))] \n",
    "    return i, row\n",
    "\n",
    "with multiprocessing.Pool(NUM_PROCESSES) as pool:\n",
    "    # Compute train NCD\n",
    "    train_data = enumerate(x_train)\n",
    "    train_results = pool.map(calculate_ncd_row, train_data)\n",
    "    \n",
    "    # Compute test NCD\n",
    "    test_data = enumerate(x_test)  \n",
    "    test_results = pool.map(calculate_ncd_row, test_data)\n",
    "    \n",
    "# Insert rows into NCD matrices    \n",
    "for i, row in train_results:\n",
    "    train_ncd[i] = row\n",
    "    \n",
    "for i, row in test_results:\n",
    "    test_ncd[i] = row\n",
    "\n",
    "# KNN classification\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "neigh.fit(train_ncd, y_train)\n",
    "\n",
    "accuracy = neigh.score(test_ncd, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
